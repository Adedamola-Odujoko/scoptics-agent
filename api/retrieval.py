import os
import weaviate
import sqlparse
from sentence_transformers import SentenceTransformer
from sqlalchemy import create_engine, text, table, column, select
from dotenv import load_dotenv


# Find the project's root directory to locate the .env file.
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
dotenv_path = os.path.join(project_root, '.env')
load_dotenv(dotenv_path=dotenv_path)

DATABASE_URL = os.getenv("DATABASE_URL")
if not DATABASE_URL:
    raise ValueError("DATABASE_URL environment variable not set.")

engine = create_engine(DATABASE_URL)

def query_events_by_filters(filters: dict):
    """
    Dynamically queries the 'events' table based on a dictionary of filters.

    Args:
        filters: A dictionary where keys are column names and values are the
                 values to filter by (e.g., {"team_id": "team_A"}).

    Returns:
        A list of dictionaries, where each dictionary represents an event.
    """
    # Define our events table using SQLAlchemy's table object
    events_table = table('events',
        column('event_id'), column('match_id'), column('event_type'),
        column('start_time'), column('end_time'), column('team_id')
        # ... add other columns as needed for retrieval
    )

    # Start with a base query: SELECT * FROM events
    query = select(events_table)

    # Dynamically build the WHERE clause based on the provided filters
    for key, value in filters.items():
        if hasattr(events_table.c, key): # Check if the column exists to be safe
            query = query.where(events_table.c[key] == value)

    # Execute the query and fetch results
    with engine.connect() as connection:
        results = connection.execute(query)
        # Convert the results to a list of dictionaries for JSON serialization
        events = [dict(row._mapping) for row in results]

    return events

# Load the embedding model once when the module is loaded.
# This is efficient as it prevents reloading the model on every API call.
print("Loading sentence-transformer model for API...")
MODEL = SentenceTransformer('all-MiniLM-L6-v2')
print("API Model loaded.")

def query_events_by_semantic(text: str, top_k: int = 5):
    """
    Searches for events in Weaviate based on semantic similarity to a text query.

    Args:
        text: The natural language query text (e.g., "fast counter attack").
        top_k: The number of top similar results to return.

    Returns:
        A list of dictionaries representing the most similar events.
    """
    # Generate the embedding for the user's query text.
    query_vector = MODEL.encode(text)

    # Connect to Weaviate and perform the search.
    # NOTE: In a high-traffic app, you might manage a persistent client pool.
    client = weaviate.connect_to_local()
    try:
        events_collection = client.collections.get("Event")

        # This is the core semantic search query.
        response = events_collection.query.near_vector(
            near_vector=query_vector,
            limit=top_k,
            # We can also ask Weaviate to include the similarity score (distance)
            return_metadata=["distance"]
        )

        # Process the results into a clean list of dictionaries.
        results = []
        for item in response.objects:
            result = {
                "properties": item.properties,
                "similarity_distance": item.metadata.distance
            }
            results.append(result)

    finally:
        client.close()

    return results
# --- (Keep all existing imports: os, sqlalchemy, dotenv, sqlparse) ---

def execute_dynamic_sql_query(sql_query: str):
    """
    Safely executes a read-only SQL query generated by an LLM.
    If an error occurs, it returns an error dictionary instead of crashing.
    """
    # 1. VALIDATE THE QUERY
    try:
        parsed = sqlparse.parse(sql_query)
        if not parsed:
            raise ValueError("Invalid SQL: Query is empty.")
        
        statement_type = parsed[0].get_type()
        if statement_type != 'SELECT':
            raise ValueError(f"Invalid SQL: Only SELECT statements are allowed. Found '{statement_type}'.")
        
        print(f"SANDBOX: SQL validation passed. Executing read-only query.")
    except Exception as e:
        return {"error": "SQL Validation Failed", "details": str(e)}

    # 2. EXECUTE USING THE RESTRICTED USER
    try:
        AI_USER_DATABASE_URL = os.getenv("DATABASE_URL").replace(
            "scoptics_user:scoptics_password",
            "ai_user:scoptics_password_readonly"
        )
        ai_engine = create_engine(AI_USER_DATABASE_URL)

        with ai_engine.connect() as connection:
            connection.execute(text("SET statement_timeout = 30000;"))
            results = connection.execute(text(sql_query))
            
            if results.returns_rows:
                query_results = [dict(row._mapping) for row in results]
            else:
                query_results = []
        
        return query_results

    # **THE FIX IS HERE:** Catch database errors and return them cleanly.
    except Exception as e:
        print(f"SANDBOX ERROR: Database execution failed. Error: {e}")
        return {"error": "Database Execution Failed", "details": str(e)}
    
    print(f"SANDBOX: SQL validation passed. Executing read-only query.")

    # 2. EXECUTE USING THE RESTRICTED USER
    # --------------------------------------------------------------------------
    # We will create a NEW engine specifically for this request, using the
    # credentials of our restricted, read-only AI user.
    AI_USER_DATABASE_URL = os.getenv("DATABASE_URL").replace(
        "scoptics_user:scoptics_password",
        "ai_user:scoptics_password_readonly" # The user/pass we created in init.sql
    )
    ai_engine = create_engine(AI_USER_DATABASE_URL)

    with ai_engine.connect() as connection:
        # We can add a statement timeout for extra protection against runaway queries.
        connection.execute(text("SET statement_timeout = 30000;")) # 30 seconds
        results = connection.execute(text(sql_query))
        
        if results.returns_rows:
            query_results = [dict(row._mapping) for row in results]
        else:
            query_results = [] # For statements that don't return rows

    return query_results